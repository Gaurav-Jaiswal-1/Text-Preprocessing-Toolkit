[metadata]
name = text-preprocessing-toolkit
version = 0.0.1
description = Automate text preprocessing tasks like tokenization, lemmatization, stop word removal, and normalization.
long_description = file: README.md
long_description_content_type = text/markdown
author = Gaurav-Jaiswal-1
author_email = jaiswalgaurav863@gmail.com
license = MIT
url = https://github.com/Gaurav-Jaiswal-1/text-preprocessing-toolkit
classifiers =
    Development Status :: 3 - Alpha
    Programming Language :: Python :: 3.8
    Programming Language :: Python :: 3.9
    Programming Language :: Python :: 3.10
    Programming Language :: Python :: 3.11
    License :: OSI Approved :: MIT License
    Operating System :: OS Independent
    Topic :: Text Processing :: Linguistic

[options]
packages = find:
python_requires = >=3.8
install_requires =
    nltk>=3.8.1
    spacy>=3.6.0

[options.extras_require]
dev =
    pytest>=7.2.0
    pytest-cov>=4.0.0
    flake8>=6.0.0
    black>=23.1.0
    mypy>=0.991
    sphinx>=7.1.2
    sphinx-rtd-theme>=1.2.0

[coverage:run]
branch = True

[coverage:report]
show_missing = True
skip_covered = True
precision = 2

[coverage:html]
directory = coverage_html_report

[coverage:xml]
output = coverage.xml

[tool:pytest]
addopts = --cov=text_preprocessing_toolkit --cov-report=term-missing --cov-report=html

[flake8]
max-line-length = 88
exclude = .git,__pycache__,docs,build,dist

[mypy]
files = text_preprocessing_toolkit
ignore_missing_imports = true
