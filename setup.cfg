[metadata]
name = text-preprocessing-toolkit
version = 0.0.1
description = Automate text preprocessing tasks like tokenization, lemmatization, stop word removal, and normalization.
long_description = file: README.md
long_description_content_type = text/markdown
author = Gaurav-Jaiswal-1
author_email = jaiswalgaurav863@gmail.com
license = MIT
url = https://github.com/Gaurav-Jaiswal-1/text-preprocessing-toolkit
classifiers =
    Development Status :: 3 - Alpha
    Programming Language :: Python :: 3.8
    Programming Language :: Python :: 3.9
    Programming Language :: Python :: 3.10
    Programming Language :: Python :: 3.11
    License :: OSI Approved :: MIT License
    Operating System :: OS Independent
    Topic :: Text Processing :: Linguistic
    Topic :: Software Development :: Libraries :: Python Modules
keywords = text preprocessing, NLP, tokenization, lemmatization, stop word removal, normalization

[options]
packages = find:
python_requires = >=3.8
install_requires =
    nltk>=3.8.1
    spacy>=3.6.0
test_suite = pytest
zip_safe = false

[options.extras_require]
dev =
    pytest>=7.2.0
    pytest-cov>=4.0.0
    flake8>=6.0.0
    black>=23.1.0
    mypy>=0.991
    sphinx>=7.1.2
    sphinx-rtd-theme>=1.2.0

[options.entry_points]
console_scripts =
    text-preprocess = Text_Preprocessing_Toolkit.main:main

[coverage:run]
branch = True
omit =
    */tests/*
    */setup.cfg
    */.tox/*

[coverage:report]
show_missing = True
skip_covered = True
precision = 2
fail_under = 80

[coverage:html]
directory = coverage_html_report

[coverage:xml]
output = coverage.xml

[tool:pytest]
addopts = --cov=Text_Preprocessing_Toolkit --cov-report=term-missing --cov-report=html --maxfail=3 --disable-warnings
testpaths = tests

[flake8]
max-line-length = 88
exclude = .git,__pycache__,docs,build,dist

[mypy]
files = Text_Preprocessing_Toolkit
ignore_missing_imports = true
